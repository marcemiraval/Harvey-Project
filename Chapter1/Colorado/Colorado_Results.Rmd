---
title: "Colorado_Results"
author: "Marcela Su√°rez"
date: "July 18, 2019"
output: html_document
---

## Intro

This document present the results obtained for Colorado:

```{r import_data, include=FALSE}

library(tidyverse) 
colorado <- read_csv("ColoradoFloodOriginal.csv") # Loading data into R

 # Create a subset with the variables to be used
library(lubridate) # For dates
colorado <- colorado %>% 
  mutate(date = ymd_hms(colorado$created_at, tz="UTC")) %>% 
  select(lat = latitude, 
         lon = longitude, 
         date = date, 
         state = c_state,
         text = t_text)
```


## Convert this dataset so that it has one-token-per-document-per-row

```{r remove_retweets}

library(tidytext)
library(stringr)

colorado <- colorado %>% 
  filter(!str_detect(text, "^RT")) # There will remain some retuits since those will be commented retweets (actually adding some info)
```

```{r clean_tweets}

colo_clean <- colorado %>% 
   mutate(text = str_remove_all(text, 'http[^ ]+'), #Finally removing urls in a nice way
          text = str_remove_all(text, '@[^ ]+'), # Removing usernames
          text = str_remove_all(text, "[:punct:]"), # Removing puntuation
          text = str_remove_all(text, "[:digit:]")) # Removing numbers
```

```{r one-token-per-document-per-row, echo=FALSE}

colo_tidy <- colo_clean %>% 
  mutate(tweet = text) %>% # To keep a column with the original tweet
  unnest_tokens(word, text, token = "tweets") %>% # add a row for each token (word) and repeat the other information
  filter(!word %in% stop_words$word, # Remove stopwords. But still need to look further into this
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"))

```


